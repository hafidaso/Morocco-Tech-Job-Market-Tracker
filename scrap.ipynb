{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42845e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-jobspy\n",
      "  Downloading python_jobspy-1.1.82-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting NUMPY==1.26.3 (from python-jobspy)\n",
      "  Downloading numpy-1.26.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (115 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from python-jobspy)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting markdownify<0.14.0,>=0.13.1 (from python-jobspy)\n",
      "  Downloading markdownify-0.13.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.0 in /opt/homebrew/lib/python3.11/site-packages (from python-jobspy) (2.3.3)\n",
      "Collecting pydantic<3.0.0,>=2.3.0 (from python-jobspy)\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting regex<2025.0.0,>=2024.4.28 (from python-jobspy)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests<3.0.0,>=2.31.0 (from python-jobspy)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tls-client<2.0.0,>=1.0.1 (from python-jobspy)\n",
      "  Downloading tls_client-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.2->python-jobspy)\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/hafida/Library/Python/3.11/lib/python/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->python-jobspy) (4.15.0)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Users/hafida/Library/Python/3.11/lib/python/site-packages (from markdownify<0.14.0,>=0.13.1->python-jobspy) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hafida/Library/Python/3.11/lib/python/site-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.3.0->python-jobspy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.3.0->python-jobspy)\n",
      "  Using cached pydantic_core-2.41.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.3.0->python-jobspy)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.31.0->python-jobspy)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.31.0->python-jobspy)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.31.0->python-jobspy)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.31.0->python-jobspy)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading python_jobspy-1.1.82-py3-none-any.whl (52 kB)\n",
      "Downloading numpy-1.26.3-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading markdownify-0.13.1-py3-none-any.whl (10 kB)\n",
      "Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-macosx_10_9_universal2.whl (206 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading tls_client-1.0.1-py3-none-any.whl (41.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: tls-client, urllib3, typing-inspection, soupsieve, regex, pydantic-core, NUMPY, idna, charset_normalizer, certifi, annotated-types, requests, pydantic, beautifulsoup4, markdownify, python-jobspy\n",
      "\u001b[2K  Attempting uninstall: NUMPY[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/16\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.5â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/16\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling numpy-2.3.5:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/16\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.5â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/16\u001b[0m [regex]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/16\u001b[0m [python-jobspy]0m [pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed NUMPY-1.26.3 annotated-types-0.7.0 beautifulsoup4-4.14.2 certifi-2025.11.12 charset_normalizer-3.4.4 idna-3.11 markdownify-0.13.1 pydantic-2.12.4 pydantic-core-2.41.5 python-jobspy-1.1.82 regex-2024.11.6 requests-2.32.5 soupsieve-2.8 tls-client-1.0.1 typing-inspection-0.4.2 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U python-jobspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6fd2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Scraper for: Casablanca, Rabat, Tanger\n",
      "ğŸ¯ Looking for roles: Data Scientist, Data Analyst, Data Engineer, Business Analyst, IngÃ©nieur Data\n",
      "\n",
      "ğŸ” Scraping: Data Scientist in Casablanca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:42:25,425 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Data%20Scientist-jobs/?page=1\n",
      "2025-11-24 17:42:25,795 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 11 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:42:38,261 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Data%20Analyst-jobs/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: Data Analyst in Casablanca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:42:38,849 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 18 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:42:50,357 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Data%20Engineer-jobs/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: Data Engineer in Casablanca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:42:50,930 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 14 jobs.\n",
      "ğŸ” Scraping: Business Analyst in Casablanca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:02,383 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Business%20Analyst-jobs/?page=1\n",
      "2025-11-24 17:43:03,029 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 17 jobs.\n",
      "ğŸ” Scraping: IngÃ©nieur Data in Casablanca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:13,697 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Ing%C3%A9nieur%20Data-jobs/?page=1\n",
      "2025-11-24 17:43:14,237 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 10 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:26,048 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Data%20Scientist-jobs/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: Data Scientist in Rabat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:26,625 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 12 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:36,203 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Data%20Analyst-jobs/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: Data Analyst in Rabat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:36,775 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 14 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:46,201 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Data%20Engineer-jobs/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: Data Engineer in Rabat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:46,444 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Found 10 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:58,270 - ERROR - JobSpy:Bayt - Bayt: Error fetching jobs - 403 Client Error: Forbidden for url: https://www.bayt.com/en/international/jobs/Business%20Analyst-jobs/?page=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: Business Analyst in Rabat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 17:43:58,841 - WARNING - JobSpy:Google - initial cursor not found, try changing your query or there was at most 10 results\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from jobspy import scrape_jobs\n",
    "import time\n",
    "\n",
    "# 1. Target Locations in Morocco\n",
    "cities = [\"Casablanca\", \"Rabat\", \"Tanger\"]\n",
    "\n",
    "# 2. Target Roles (English & French mix for best results)\n",
    "roles = [\n",
    "    \"Data Scientist\", \n",
    "    \"Data Analyst\", \n",
    "    \"Data Engineer\",\n",
    "    \"Business Analyst\",\n",
    "    \"IngÃ©nieur Data\" # Added French title\n",
    "]\n",
    "\n",
    "# 3. Sites to Scrape\n",
    "# Added \"bayt\" because it is very popular in Morocco/MENA\n",
    "sites = [\"indeed\", \"linkedin\", \"google\", \"bayt\"] \n",
    "\n",
    "all_jobs_list = []\n",
    "\n",
    "print(f\"ğŸš€ Starting Scraper for: {', '.join(cities)}\")\n",
    "print(f\"ğŸ¯ Looking for roles: {', '.join(roles)}\\n\")\n",
    "\n",
    "for city in cities:\n",
    "    for role in roles:\n",
    "        print(f\"ğŸ” Scraping: {role} in {city}...\")\n",
    "        \n",
    "        try:\n",
    "            jobs = scrape_jobs(\n",
    "                site_name=sites,\n",
    "                search_term=role,\n",
    "                google_search_term=f\"{role} jobs in {city} Morocco\",\n",
    "                location=f\"{city}, Morocco\",\n",
    "                \n",
    "                results_wanted=10,  # Keep low (10-20) per loop to avoid IP bans\n",
    "                hours_old=168,      # Past 7 days\n",
    "                \n",
    "                # CRITICAL FOR MOROCCO\n",
    "                country_indeed='Morocco', \n",
    "                \n",
    "                # CRITICAL FOR YOUR PROJECT (NLP)\n",
    "                # This fetches the full text so you can extract \"Python\", \"SQL\" later.\n",
    "                linkedin_fetch_description=True, \n",
    "                \n",
    "                # Clean output\n",
    "                verbose=1 \n",
    "            )\n",
    "            \n",
    "            if not jobs.empty:\n",
    "                # Tag data for your Dashboard\n",
    "                jobs['searched_city'] = city\n",
    "                jobs['searched_role'] = role\n",
    "                all_jobs_list.append(jobs)\n",
    "                print(f\"   âœ… Found {len(jobs)} jobs.\")\n",
    "            else:\n",
    "                print(\"   âš ï¸ No jobs found.\")\n",
    "            \n",
    "            # Pause to be polite to the servers\n",
    "            time.sleep(3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error: {e}\")\n",
    "\n",
    "# 4. Merge and Save\n",
    "if all_jobs_list:\n",
    "    combined_jobs = pd.concat(all_jobs_list, ignore_index=True)\n",
    "    \n",
    "    # Clean duplicates (e.g. same job on Indeed AND Google)\n",
    "    combined_jobs.drop_duplicates(subset=['title', 'company'], keep='first', inplace=True)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Total Unique Jobs: {len(combined_jobs)}\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = \"morocco_data_market.csv\"\n",
    "    combined_jobs.to_csv(filename, quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)\n",
    "    print(f\"ğŸ’¾ Data saved to '{filename}'\")\n",
    "    \n",
    "    # Preview columns to ensure you have descriptions\n",
    "    print(\"\\nColumns captured:\")\n",
    "    print(combined_jobs.columns.tolist())\n",
    "else:\n",
    "    print(\"\\nğŸ˜” No jobs found. Check your internet connection or proxies.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
